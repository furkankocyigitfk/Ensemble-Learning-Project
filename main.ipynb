{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGH4MVKYxzwc",
        "outputId": "7d39ca05-a77e-4aef-d8c9-f79ecd0332fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "os.chdir(\"drive/MyDrive/Kolektif Öğrenme/project\")\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc_Rdc5Hx4nz",
        "outputId": "d87d5967-c05c-4f58-b26d-be56c1c30819"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/Kolektif Öğrenme/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGMHiqNzyNH7",
        "outputId": "d0ebc595-579c-4ed7-cb7f-5edd063c491c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.8/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.8/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dciUR7kpxs-H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import twitter_samples\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, MaxPooling2D, Flatten, Dropout, Input, Lambda\n",
        "from keras.models import Model\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EekpOXXRxs-S"
      },
      "outputs": [],
      "source": [
        "def cleaning(text):\n",
        "    text = [txt.lower() for txt in re.findall(r\"(?:^|(?<= ))[a-zA-Z]+(?= |$)\", text)]\n",
        "    text = remove_stopwords(\" \".join(text))\n",
        "\n",
        "    return \"no text\" if len(text) == 0 else text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7NnEuMtxs-Y",
        "outputId": "6c3b784b-c3b1-4af1-ff6e-ecb87637b419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "nltk.download(\"twitter_samples\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "81MKP_Dbxs-f"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(twitter_samples.strings(\"positive_tweets.json\"), columns=[\"sentence\"])\n",
        "df2 = pd.DataFrame(twitter_samples.strings(\"negative_tweets.json\"), columns=[\"sentence\"])\n",
        "df[\"result\"] = 1\n",
        "df2[\"result\"] = 0\n",
        "df = pd.concat([df, df2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qbEQAwGSxs-j",
        "outputId": "5f675bc1-12ac-49e5-fd8b-69cde4efb831"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  result\n",
              "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...       1\n",
              "1  @Lamb2ja Hey James! How odd :/ Please call our...       1\n",
              "2  @DespiteOfficial we had a listen last night :)...       1\n",
              "3                               @97sides CONGRATS :)       1\n",
              "4  yeaaaah yippppy!!!  my accnt verified rqst has...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51777791-aeef-4185-85eb-b9d45f48a851\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@97sides CONGRATS :)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51777791-aeef-4185-85eb-b9d45f48a851')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51777791-aeef-4185-85eb-b9d45f48a851 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51777791-aeef-4185-85eb-b9d45f48a851');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d_ikAztFxs-n"
      },
      "outputs": [],
      "source": [
        "df[\"sentence\"] = df[\"sentence\"].apply(cleaning)\n",
        "df = df[df[\"sentence\"] != \"no text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8X-N5wFxs-s",
        "outputId": "ab5bd28e-6809-4bcf-ae55-197e5944cafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 9530 entries, 0 to 4999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   sentence  9530 non-null   object\n",
            " 1   result    9530 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 223.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HfzH3LJtxs-u"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "from transformers import BertTokenizer, TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VZfKs52_xs-z"
      },
      "outputs": [],
      "source": [
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\", trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIN2JnBQxs-2",
        "outputId": "55173325-17bc-49d0-dddd-75366a33dc4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)\n",
        "\n",
        "def encoder(sentences):\n",
        "  ids = []\n",
        "  for sentence in sentences:\n",
        "    encoding = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    max_length=16,\n",
        "    truncation = True,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=False,\n",
        "    pad_to_max_length=True,\n",
        "    return_attention_mask=False)\n",
        "    ids.append(encoding[\"input_ids\"])\n",
        "  return ids\n",
        "\n",
        "train_sents,test_sents, train_labels, test_labels  = train_test_split(df[\"sentence\"],df[\"result\"], test_size=0.2, stratify=df.result)\n",
        "\n",
        "train_ids = encoder(train_sents)\n",
        "test_ids = encoder(test_sents) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HonSkqFExs-8"
      },
      "outputs": [],
      "source": [
        "train_ids = tf.convert_to_tensor(train_ids)\n",
        "test_ids = tf.convert_to_tensor(test_ids)\n",
        "test_labels = tf.convert_to_tensor(test_labels)\n",
        "train_labels = tf.convert_to_tensor(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9HGFaFfxs--",
        "outputId": "12405163-aad5-4495-ebfc-d917012939d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "max_len=500\n",
        "bert_encoder = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "input_word_ids = Input(shape=(16,), dtype=tf.int32, name=\"input_word_ids\")  \n",
        "embedding = bert_encoder([input_word_ids])\n",
        "dense = Lambda(lambda seq: seq[:, 0, :])(embedding[0])\n",
        "dense = Dense(128, activation=\"relu\",kernel_regularizer=\"l2\")(dense)\n",
        "output = Dense(1, activation=\"sigmoid\",kernel_regularizer=\"l2\")(dense)    \n",
        "\n",
        "model = Model(inputs=[input_word_ids], outputs=output)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1CLwJ4dxs_A",
        "outputId": "ad310598-7697-449d-b280-b76ddb02466a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 34s 199ms/step - loss: 1.9894 - accuracy: 0.5086\n",
            "Epoch 2/5\n",
            "125/125 [==============================] - 25s 202ms/step - loss: 1.0206 - accuracy: 0.4913\n",
            "Epoch 3/5\n",
            "125/125 [==============================] - 25s 203ms/step - loss: 0.8030 - accuracy: 0.4956\n",
            "Epoch 4/5\n",
            "125/125 [==============================] - 26s 208ms/step - loss: 0.7388 - accuracy: 0.4989\n",
            "Epoch 5/5\n",
            "125/125 [==============================] - 26s 208ms/step - loss: 0.7208 - accuracy: 0.5027\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "train_history = model.fit(train_ids, train_labels, epochs = 5, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-yewuaxs_C",
        "outputId": "68db0fee-4607-49cf-f93b-9e3443d3b004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_word_ids (InputLayer)  [(None, 16)]             0         \n",
            "                                                                 \n",
            " tf_bert_model_1 (TFBertMode  TFBaseModelOutputWithPoo  109482240\n",
            " l)                          lingAndCrossAttentions(l            \n",
            "                             ast_hidden_state=(None,             \n",
            "                             16, 768),                           \n",
            "                              pooler_output=(None, 76            \n",
            "                             8),                                 \n",
            "                              past_key_values=None, h            \n",
            "                             idden_states=None, atten            \n",
            "                             tions=None, cross_attent            \n",
            "                             ions=None)                          \n",
            "                                                                 \n",
            " lambda_1 (Lambda)           (None, 768)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,482,240\n",
            "Trainable params: 109,482,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "bert_encoder = Model(input_word_ids, model.get_layer(list(filter(lambda x: \"lambda\" in x.name,  model.layers))[0].name).output)\n",
        "bert_encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYTMCrWCxs_E",
        "outputId": "283bc6f7-f85d-413f-a911-0639a1702697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 9s 29ms/step\n",
            "63/63 [==============================] - 5s 46ms/step\n"
          ]
        }
      ],
      "source": [
        "train_embed = bert_encoder.predict(train_ids)\n",
        "test_embed = bert_encoder.predict(test_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DWwUsBiTxs_F"
      },
      "outputs": [],
      "source": [
        "def generate_imp_space(X_train, y_train, X_test, imp_feature_size, foz):\n",
        "    imp_train_data = X_train.values\n",
        "    imp_test_data = X_test.values\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "    d = len(X_train.columns)\n",
        "\n",
        "    for i in range(0, imp_feature_size*foz):\n",
        "        Xindis = np.random.permutation(d)\n",
        "        for j in range(0, d-(foz-1), foz):\n",
        "            sX = np.random.permutation(1)\n",
        "            s1 = sX[0]\n",
        "\n",
        "            s1data = X_train[X_train.index.isin(y_train[y_train == str(s1)].index)]\n",
        "            s2data = X_train[~X_train.index.isin(y_train[y_train == str(s1)].index)]\n",
        "            s1data = s1data.iloc[:, Xindis[j:j+(foz)]]\n",
        "            s2data = s2data.iloc[:, Xindis[j:j+(foz)]]\n",
        "\n",
        "            s1label = np.ones((s1data.values.shape[0], 1), dtype=int)\n",
        "            s2label = -1*np.ones((s2data.values.shape[0], 1), dtype=int)\n",
        "            Wdata = np.concatenate((s1data, s2data))\n",
        "\n",
        "            Wdata = x2fx(Wdata)\n",
        "            Wlabel = np.concatenate((s1label, s2label))\n",
        "            W = np.matmul(np.matmul(np.linalg.pinv(\n",
        "                np.matmul(Wdata.T, Wdata)), Wdata.T), Wlabel)\n",
        "\n",
        "            WW = x2fx(X_train.iloc[:, Xindis[j:j+(foz)]].values)\n",
        "            imp_train_data = np.concatenate(\n",
        "                (imp_train_data, np.matmul(WW, W)), axis=1)\n",
        "\n",
        "            TT = x2fx(X_test.iloc[:, Xindis[j:j+(foz)]].values)\n",
        "            imp_test_data = np.concatenate(\n",
        "                (imp_test_data, np.matmul(TT, W)), axis=1)\n",
        "\n",
        "    return imp_train_data, imp_test_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0HNn8iPjxs_H"
      },
      "outputs": [],
      "source": [
        "def x2fx(x, model=\"linear\"):\n",
        "    linear = np.c_[np.ones(x.shape[0]), x]\n",
        "    if model == \"linear\":\n",
        "        return linear\n",
        "    if model == \"purequadratic\":\n",
        "        return np.c_[linear, x**2]\n",
        "    interaction = np.hstack([x[:, i]*x[:, j]\n",
        "                            for i, j in comb(range(x.shape[1]), 2)]).T\n",
        "    if model == \"interaction\":\n",
        "        return np.c_[linear, interaction]\n",
        "    if model == \"quadratic\":\n",
        "        return np.c_[linear, interaction, x**2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0xKxNJUIxs_J"
      },
      "outputs": [],
      "source": [
        "foz = 4\n",
        "imp_feature_size = 1\n",
        "n_estimators = 3\n",
        "imp_acc = []\n",
        "rfc_acc = []\n",
        "estimators_imp = []\n",
        "estimators = []\n",
        "train_embed = pd.DataFrame(train_embed)\n",
        "test_embed=pd.DataFrame(test_embed)\n",
        "d = len(train_embed.columns)\n",
        "\n",
        "for i in range(n_estimators):\n",
        "    imp_tr, imp_ts = generate_imp_space(train_embed, train_labels, test_embed, imp_feature_size, foz)\n",
        "    imp_d = imp_tr.shape[1]\n",
        "\n",
        "    imp_sel_d = 2 * round(math.log2(imp_d))\n",
        "    sel_d = 2*round(math.log2(d))\n",
        "\n",
        "    imp_rfc = RandomForestClassifier(max_features=imp_sel_d, n_estimators=50, random_state=42)\n",
        "    imp_rfc.fit(imp_tr, train_labels)\n",
        "    estimators_imp.append((\"imp_rfc\"+str(i), imp_rfc))\n",
        "\n",
        "    rfc = RandomForestClassifier(max_features=sel_d, n_estimators=50, random_state=42)\n",
        "    rfc.fit(train_embed, train_labels)\n",
        "    estimators.append((\"rfc\"+str(i), rfc))\n",
        "\n",
        "\n",
        "voting_imp = VotingClassifier(estimators=estimators_imp)\n",
        "voting_imp.fit(imp_tr, train_labels)\n",
        "\n",
        "voting_rfc = VotingClassifier(estimators=estimators)\n",
        "voting_rfc.fit(train_embed, train_labels)\n",
        "\n",
        "imp_acc.append(voting_imp.score(imp_ts, test_labels))\n",
        "rfc_acc.append(voting_rfc.score(test_embed, test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imp_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEuJGVsA0-zp",
        "outputId": "0aa1172f-c55e-4f83-e96c-2e766e0e3c9b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6415]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdjarZBJ0_4R",
        "outputId": "c01f4a94-8a24-4d86-c1c5-df7009502175"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.648]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsTz_TsYxs_K",
        "outputId": "7310e248-e168-44a2-d1ff-4c5ba94782c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5550891920251836]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "imp_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7C2_4fBxs_M",
        "outputId": "6f576686-b433-4f68-c198-c82ffee5716e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.55299055613851]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "rfc_acc"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "65a922febd0a5868ed12620df141547b754242d19c66cf1750f84ba43717be07"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}